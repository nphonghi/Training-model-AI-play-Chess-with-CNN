{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-chess in ./myenv/lib/python3.12/site-packages (1.999)\n",
      "Requirement already satisfied: chess<2,>=1 in ./myenv/lib/python3.12/site-packages (from python-chess) (1.11.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install python-chess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: patool in ./myenv/lib/python3.12/site-packages (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install patool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nguyennhatphong/Documents/ChessTrainAI/myenv/bin/python3.12\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./myenv/lib/python3.12/site-packages (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in ./myenv/lib/python3.12/site-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./myenv/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./myenv/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./myenv/lib/python3.12/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./myenv/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./myenv/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./myenv/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./myenv/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in ./myenv/lib/python3.12/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in ./myenv/lib/python3.12/site-packages (from tensorflow) (5.29.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./myenv/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in ./myenv/lib/python3.12/site-packages (from tensorflow) (75.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./myenv/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./myenv/lib/python3.12/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./myenv/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./myenv/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./myenv/lib/python3.12/site-packages (from tensorflow) (1.68.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in ./myenv/lib/python3.12/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in ./myenv/lib/python3.12/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in ./myenv/lib/python3.12/site-packages (from tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in ./myenv/lib/python3.12/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in ./myenv/lib/python3.12/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./myenv/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in ./myenv/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in ./myenv/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in ./myenv/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./myenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./myenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./myenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./myenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./myenv/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./myenv/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./myenv/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./myenv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./myenv/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./myenv/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./myenv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./myenv/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./myenv/lib/python3.12/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./myenv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./myenv/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./myenv/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in ./myenv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in ./myenv/lib/python3.12/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./myenv/lib/python3.12/site-packages (from scikit-learn) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./myenv/lib/python3.12/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./myenv/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./myenv/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import chess.engine\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import patoolib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bitmaps(fen):\n",
    "    board = chess.Board(fen)\n",
    "    \n",
    "    piece_index_map = {\n",
    "        'k': 0,  'K': 6,\n",
    "        'q': 1,  'Q': 7,\n",
    "        'r': 2,  'R': 8,\n",
    "        'n': 3,  'N': 9,\n",
    "        'b': 4,  'B': 10,\n",
    "        'p': 5,  'P': 11\n",
    "    }\n",
    "\n",
    "    material_value_map = {\n",
    "        'k': 0,  'K': 0,\n",
    "        'q': -9, 'Q': 9,\n",
    "        'r': -5, 'R': 5,\n",
    "        'n': -3, 'N': 3,\n",
    "        'b': -3, 'B': 3,\n",
    "        'p': -1, 'P': 1\n",
    "    }\n",
    "\n",
    "    file_mapping = 'abcdefgh'\n",
    "    bitmap = np.zeros((14, 8, 8))\n",
    "\n",
    "    fen_parts = fen.split(' ')\n",
    "    position_data = fen_parts[0]\n",
    "\n",
    "    row, col = 0, 0\n",
    "    white_material, black_material = 0, 0\n",
    "\n",
    "    for char in position_data:\n",
    "        if char.isdigit():\n",
    "            col += int(char)\n",
    "        elif char == '/':\n",
    "            row += 1\n",
    "            col = 0\n",
    "        else:\n",
    "            piece_index = piece_index_map[char]\n",
    "            value = 1 if char.isupper() else -1\n",
    "            \n",
    "            bitmap[piece_index, row, col] = value\n",
    "\n",
    "            if char.isupper():\n",
    "                white_material += material_value_map[char]\n",
    "            else:\n",
    "                black_material += material_value_map[char]\n",
    "\n",
    "            col += 1\n",
    "\n",
    "    legal_moves_layer = 12 if board.turn else 13\n",
    "    opponent_moves_layer = 13 if board.turn else 12\n",
    "\n",
    "    for move in board.legal_moves:\n",
    "        target_col = file_mapping.index(str(move)[2])\n",
    "        target_row = int(str(move)[3]) - 1\n",
    "        bitmap[legal_moves_layer, target_row, target_col] = 1\n",
    "\n",
    "    board.turn = not board.turn\n",
    "\n",
    "    for move in board.legal_moves:\n",
    "        target_col = file_mapping.index(str(move)[2])\n",
    "        target_row = int(str(move)[3]) - 1\n",
    "        bitmap[opponent_moves_layer, target_row, target_col] = 1\n",
    "\n",
    "    bitmap[12] = np.flipud(bitmap[12])\n",
    "    bitmap[13] = np.flipud(bitmap[13])\n",
    "\n",
    "    return bitmap, white_material, black_material\n",
    "\n",
    "def generate_compressed_bitmaps(fen):\n",
    "    board = chess.Board(fen)\n",
    "\n",
    "    piece_index_map = {\n",
    "        'k': 0,  'K': 0,\n",
    "        'q': 1,  'Q': 1,\n",
    "        'r': 2,  'R': 2,\n",
    "        'n': 3,  'N': 3,\n",
    "        'b': 4,  'B': 4,\n",
    "        'p': 5,  'P': 5\n",
    "    }\n",
    "\n",
    "    material_value_map = {\n",
    "        'k': 0,  'K': 0,\n",
    "        'q': -9, 'Q': 9,\n",
    "        'r': -5, 'R': 5,\n",
    "        'n': -3, 'N': 3,\n",
    "        'b': -3, 'B': 3,\n",
    "        'p': -1, 'P': 1\n",
    "    }\n",
    "\n",
    "    file_mapping = 'abcdefgh'\n",
    "    bitmap = np.zeros((8, 8, 8))\n",
    "\n",
    "    fen_parts = fen.split(' ')\n",
    "    position_data = fen_parts[0]\n",
    "\n",
    "    row, col = 0, 0\n",
    "    white_material, black_material = 0, 0\n",
    "\n",
    "    for char in position_data:\n",
    "        if char.isdigit():\n",
    "            col += int(char)\n",
    "        elif char == '/':\n",
    "            row += 1\n",
    "            col = 0\n",
    "        else:\n",
    "            piece_index = piece_index_map[char]\n",
    "            value = 1 if char.isupper() else -1\n",
    "            \n",
    "            bitmap[piece_index, row, col] = value\n",
    "\n",
    "            if char.isupper():\n",
    "                white_material += material_value_map[char]\n",
    "            else:\n",
    "                black_material += material_value_map[char]\n",
    "\n",
    "            col += 1\n",
    "\n",
    "    legal_moves_layer = 6 if board.turn else 7\n",
    "    opponent_moves_layer = 7 if board.turn else 6\n",
    "\n",
    "    for move in board.legal_moves:\n",
    "        target_col = file_mapping.index(str(move)[2])\n",
    "        target_row = int(str(move)[3]) - 1\n",
    "        bitmap[legal_moves_layer, target_row, target_col] = 1\n",
    "\n",
    "    board.turn = not board.turn\n",
    "\n",
    "    for move in board.legal_moves:\n",
    "        target_col = file_mapping.index(str(move)[2])\n",
    "        target_row = int(str(move)[3]) - 1\n",
    "        bitmap[opponent_moves_layer, target_row, target_col] = 1\n",
    "\n",
    "    bitmap[6] = np.flipud(bitmap[6])\n",
    "    bitmap[7] = np.flipud(bitmap[7])\n",
    "\n",
    "    return bitmap, white_material, black_material\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('chessData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data(sample_size, dataframe):\n",
    "    \"\"\"\n",
    "    Generate training data from a given DataFrame containing FEN strings and evaluations.\n",
    "\n",
    "    Parameters:\n",
    "    - sample_size (int): Number of samples to process.\n",
    "    - dataframe (pd.DataFrame): DataFrame containing 'FEN' and 'Evaluation' columns.\n",
    "\n",
    "    Returns:\n",
    "    - x (np.array): Array of shape (samples, 1, 8, 8, 8) representing board states.\n",
    "    - y (np.array): Array of shape (samples,) containing adjusted evaluations.\n",
    "    \"\"\"\n",
    "    bitmaps = []\n",
    "    adjusted_evaluations = []\n",
    "\n",
    "    for index in dataframe.index[:sample_size]:\n",
    "        row = dataframe.iloc[index]\n",
    "        \n",
    "        # Generate compressed bitmap and material difference\n",
    "        try:\n",
    "            board_bitmap, white_material, black_material = generate_compressed_bitmaps(row['FEN'])\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing FEN: {row['FEN']}. Skipping. Error: {e}\")\n",
    "            continue\n",
    "\n",
    "        material_difference = white_material + black_material\n",
    "\n",
    "        # Parse evaluation value\n",
    "        eval_string = row['Evaluation']\n",
    "        try:\n",
    "            if '#' in eval_string:  # Checkmate cases\n",
    "                evaluation = int(eval_string[1:])\n",
    "            else:\n",
    "                evaluation = int(eval_string)\n",
    "        except ValueError:\n",
    "            print(f\"Invalid evaluation: {eval_string}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Adjust evaluation and add material difference\n",
    "        adjusted_eval = (evaluation / 100) + material_difference\n",
    "\n",
    "        # Append data\n",
    "        bitmaps.append(board_bitmap)\n",
    "        adjusted_evaluations.append(adjusted_eval)\n",
    "\n",
    "    # Convert lists to NumPy arrays\n",
    "    x = np.array(bitmaps, dtype=np.float32)\n",
    "    x = x.reshape(x.shape[0], 1, 8, 8, 8)  # Reshape for CNN/RNN input\n",
    "    \n",
    "    y = np.array(adjusted_evaluations, dtype=np.float32)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv3d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv3d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">62,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv3d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,504</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv3d (\u001b[38;5;33mConv3D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m48\u001b[0m)    │        \u001b[38;5;34m10,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m48\u001b[0m)    │           \u001b[38;5;34m192\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv3d_1 (\u001b[38;5;33mConv3D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m48\u001b[0m)    │        \u001b[38;5;34m62,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m48\u001b[0m)    │           \u001b[38;5;34m192\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv3d_2 (\u001b[38;5;33mConv3D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │        \u001b[38;5;34m41,504\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m65,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">181,345</span> (708.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m181,345\u001b[0m (708.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">181,089</span> (707.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m181,089\u001b[0m (707.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_chess_evaluation_model():\n",
    "    \"\"\"\n",
    "    Builds a Convolutional Neural Network model for chess position evaluation.\n",
    "    \n",
    "    Returns:\n",
    "        model (tf.keras.Model): Compiled Keras model ready for training.\n",
    "    \"\"\"\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Input layer with shape (1, 8, 8, 8)\n",
    "    model.add(layers.Input(shape=(1, 8, 8, 8)))\n",
    "\n",
    "    # Convolutional layers with ReLU activation and Batch Normalization\n",
    "    model.add(layers.Conv3D(48, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Conv3D(48, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Conv3D(32, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    # Flatten layer to convert 2D feature maps to 1D\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # Dense layers for final evaluation\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "\n",
    "    # Output layer with a single neuron for evaluation score\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    # Model compilation\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Build and summarize the model\n",
    "chess_model = build_chess_evaluation_model()\n",
    "chess_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 36.5406 - mse: 36.5406\n",
      "Epoch 1: loss improved from inf to 32.75726, saving model to best_chess_model.keras\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 166ms/step - loss: 36.5309 - mse: 36.5309\n",
      "Epoch 2/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 24.3726 - mse: 24.3726\n",
      "Epoch 2: loss improved from 32.75726 to 24.09322, saving model to best_chess_model.keras\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 181ms/step - loss: 24.3719 - mse: 24.3719\n",
      "Epoch 3/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 18.6466 - mse: 18.6466\n",
      "Epoch 3: loss improved from 24.09322 to 18.72075, saving model to best_chess_model.keras\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 188ms/step - loss: 18.6468 - mse: 18.6468\n",
      "Epoch 4/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 14.8442 - mse: 14.8442\n",
      "Epoch 4: loss improved from 18.72075 to 15.03814, saving model to best_chess_model.keras\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 191ms/step - loss: 14.8447 - mse: 14.8447\n",
      "Epoch 5/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 12.7222 - mse: 12.7222\n",
      "Epoch 5: loss improved from 15.03814 to 12.92440, saving model to best_chess_model.keras\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 191ms/step - loss: 12.7227 - mse: 12.7227\n",
      "Epoch 6/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 10.4313 - mse: 10.4313\n",
      "Epoch 6: loss improved from 12.92440 to 10.97767, saving model to best_chess_model.keras\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 193ms/step - loss: 10.4327 - mse: 10.4327\n",
      "Epoch 7/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 9.3784 - mse: 9.3784\n",
      "Epoch 7: loss improved from 10.97767 to 9.75286, saving model to best_chess_model.keras\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 199ms/step - loss: 9.3793 - mse: 9.3793\n",
      "Epoch 8/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 8.3569 - mse: 8.3569\n",
      "Epoch 8: loss improved from 9.75286 to 8.63536, saving model to best_chess_model.keras\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 198ms/step - loss: 8.3576 - mse: 8.3576\n",
      "Epoch 9/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 7.5388 - mse: 7.5388\n",
      "Epoch 9: loss improved from 8.63536 to 7.81156, saving model to best_chess_model.keras\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 197ms/step - loss: 7.5395 - mse: 7.5395\n",
      "Epoch 10/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 6.8933 - mse: 6.8933\n",
      "Epoch 10: loss improved from 7.81156 to 7.03223, saving model to best_chess_model.keras\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 200ms/step - loss: 6.8936 - mse: 6.8936\n",
      "Epoch 11/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 6.5170 - mse: 6.5170\n",
      "Epoch 11: loss improved from 7.03223 to 6.51675, saving model to best_chess_model.keras\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 201ms/step - loss: 6.5169 - mse: 6.5169\n",
      "Epoch 12/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 6.0038 - mse: 6.0038\n",
      "Epoch 12: loss improved from 6.51675 to 6.12169, saving model to best_chess_model.keras\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 200ms/step - loss: 6.0041 - mse: 6.0041\n",
      "Epoch 13/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 5.5502 - mse: 5.5502\n",
      "Epoch 13: loss improved from 6.12169 to 5.62263, saving model to best_chess_model.keras\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 204ms/step - loss: 5.5504 - mse: 5.5504\n",
      "Epoch 14/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - loss: 5.1943 - mse: 5.1943\n",
      "Epoch 14: loss improved from 5.62263 to 5.21454, saving model to best_chess_model.keras\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 240ms/step - loss: 5.1943 - mse: 5.1943\n",
      "Epoch 15/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 4.5645 - mse: 4.5645\n",
      "Epoch 15: loss improved from 5.21454 to 4.79821, saving model to best_chess_model.keras\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 202ms/step - loss: 4.5651 - mse: 4.5651\n",
      "Epoch 16/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 4.6497 - mse: 4.6497\n",
      "Epoch 16: loss did not improve from 4.79821\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 213ms/step - loss: 4.6501 - mse: 4.6501\n",
      "Epoch 17/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - loss: 4.3444 - mse: 4.3444\n",
      "Epoch 17: loss improved from 4.79821 to 4.46925, saving model to best_chess_model.keras\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 220ms/step - loss: 4.3447 - mse: 4.3447\n",
      "Epoch 18/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 4.2120 - mse: 4.2120\n",
      "Epoch 18: loss improved from 4.46925 to 4.35146, saving model to best_chess_model.keras\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 211ms/step - loss: 4.2124 - mse: 4.2124\n",
      "Epoch 19/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 4.1883 - mse: 4.1883\n",
      "Epoch 19: loss improved from 4.35146 to 4.17521, saving model to best_chess_model.keras\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 211ms/step - loss: 4.1883 - mse: 4.1883\n",
      "Epoch 20/20\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 3.9454 - mse: 3.9454\n",
      "Epoch 20: loss improved from 4.17521 to 4.06109, saving model to best_chess_model.keras\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 204ms/step - loss: 3.9457 - mse: 3.9457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x158e2e390>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Đường dẫn để lưu mô hình tốt nhất\n",
    "checkpoint_path = \"best_chess_model.keras\"\n",
    "\n",
    "# Tạo dữ liệu huấn luyện\n",
    "num_samples = 200000\n",
    "x_train, y_train = create_training_data(num_samples, dataframe)\n",
    "\n",
    "# Tạo callback để lưu mô hình tốt nhất dựa trên giá trị mất mát nhỏ nhất trên tập huấn luyện\n",
    "checkpoint_callback = ModelCheckpoint(filepath=checkpoint_path, save_best_only=True, monitor='loss', mode='min', verbose=1)\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "chess_model.fit(x_train, y_train, epochs=20, batch_size=512, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
